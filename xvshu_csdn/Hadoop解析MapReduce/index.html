<div style="color:blue" align=center>Hadoop解析MapReduce</div><br><div id="article_content" class="article_content tracking-ad" data-mod="popu_307" data-dsm="post">

<p><span style="font-size:18px">从本篇博客开始咱们一起来详细了解Hadoop的每个部分，我们在上篇博客中介绍了HDFS，MapReduce，MapReduce为了更有效率其实是建立在HDFS之上的，有了分布式的文件系统，我们就能在这个系统之上更有效率地进行分布式的计算，我们看看它是咱么实现更优秀的分布式计算。</span></p>
<h1><span style="font-size:18px">优势</span></h1>
<p><span style="font-size:18px">第一，大小限制</span></p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; 因为HDFS对本地的文件大小做了限制，这样我们本地一个任务处理的量是有限的，虽然我们可以改变这个&#20540;，但是也为更好的执行任务打下了坚实的基础，分片的处理方式，不仅仅是分开，还有限制，这样的思想使我们欠缺的，分开仅仅是解决了问你，而限制，是在优化解决方案！</span></p>
<p><span style="font-size:18px"><br>
</span></p>
<p><span style="font-size:18px">第二，备份</span></p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; HDFS对所有的文件，都会进行备份，这样就会减少很多麻烦，我们以往对文件的备份还原一直是个头疼的问题，尤其是数据量上来之后，这件事情变得越来越不可控，而HDFS为计算数据做了备份，这样我们的失误率就会下降，在一台机器文件毁坏的情况下，不影响我们的计算，这就减少了查询日志的时间（相对传统数据库的备份策略）</span></p>
<p><span style="font-size:18px"><br>
</span></p>
<p><span style="font-size:18px">第三，本地计算</span></p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;MapReduce中，所有的计算，都是在本地完成，及时有计算需要外来数据，也是集合好后完成，这样保证了我们最高效的带宽利用，使我们对数据的处理能力随着集群数目的增大而线性增大。</span></p>
<p><span style="font-size:18px"><br>
</span></p>
<p><span style="font-size:18px">第四，预处理</span></p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; 在计算的过程中，如果我们对数据的处理结果每次都要控制机进行汇总，和我们可以对计算出的数据，进行预处理，当然是预处理的效果好些，这样相当于减轻了控制机的压力，这种设计在前台js里也有涉及，我们通过js让客户机执行部分代码，减轻我们服务器的压力，这样的效果，自然是比较优秀的！</span></p>
<p><span style="font-size:18px"><br>
</span></p>
<p><span style="font-size:18px">第五，心跳</span></p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; 在MapReduce过程中，心跳对我们的帮助也很大，它帮助我们维护计算的可靠性，帮助我们屏蔽一部分因机器故障造成的计算失败，相当于心跳是我们计算过程中基本的保证！</span></p>
<h1><span style="font-size:18px">原理</span></h1>
<p><span style="font-size:18px">那么mapreduce是怎么做的呢，我们看看这幅原理图：</span></p>
<p><span style="font-size:18px"><img src="30431618768328" align="middle" width="1200" height="270" alt=""><br>
</span></p>
<p><span style="font-size:18px">再看看一些细节上的图，帮我们这里了解下具体是怎么运行的：</span></p>
<p><span style="font-size:18px"><img src="26937909277449" alt=""><br>
</span></p>
<h1><span style="font-size:18px">源码</span></h1>
<p><span style="font-size:18px">有了前面的认识，我们通过代码看看，我们要秉着一个原则，就是这是简单的分治法的应用，所以这一切都不复杂，map就是分治法的分，reduce就是分治法的治，将大问题打散成小问题，最后整合小问题的结果：</span></p>
<p><span style="font-size:18px">map：</span></p>
<p>
<pre name="code" class="java">public static class Map extends MapReduceBase implements 
            Mapper&lt;LongWritable, Text, Text, IntWritable&gt; { 
        private final static IntWritable one = new IntWritable(1); 
        private Text word = new Text();
        public void map(LongWritable key, Text value, 
                OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter) 
                throws IOException { 
            String line = value.toString(); 
            StringTokenizer tokenizer = new StringTokenizer(line); 
            while (tokenizer.hasMoreTokens()) { 
                word.set(tokenizer.nextToken()); 
                output.collect(word, one); 
            } 
        } 
    }</pre><span style="font-size:18px"><br>
reduce：</span>
<p>
<p>
<pre name="code" class="java"> public static class Reduce extends MapReduceBase implements 
            Reducer&lt;Text, IntWritable, Text, IntWritable&gt; { 
        public void reduce(Text key, Iterator&lt;IntWritable&gt; values, 
                OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter) 
                throws IOException { 
            int sum = 0; 
            while (values.hasNext()) { 
                sum += values.next().get(); 
            } 
            output.collect(key, new IntWritable(sum)); 
        } 
    }</pre><span style="font-size:18px"><br>
任务执行的方法：</span>
<p>
<p>
<pre name="code" class="java">public static void main(String[] args) throws Exception { 
        JobConf conf = new JobConf(WordCount.class); 
        conf.setJobName(&quot;wordcount&quot;);
        conf.setOutputKeyClass(Text.class); 
        conf.setOutputValueClass(IntWritable.class);
        conf.setMapperClass(Map.class); 
        conf.setCombinerClass(Reduce.class); 
        conf.setReducerClass(Reduce.class);
        conf.setInputFormat(TextInputFormat.class); 
        conf.setOutputFormat(TextOutputFormat.class);
        FileInputFormat.setInputPaths(conf, new Path(args[0])); 
        FileOutputFormat.setOutputPath(conf, new Path(args[1]));
        JobClient.runJob(conf); 
    } </pre>
<p>
<p><span style="font-size:18px"><br>
</span></p>
<span style="font-size:18px">任务方法解析：</span>
<p><span style="font-size:18px">首先讲解一下 Job 的 初始化过程 。 main 函数调用 Jobconf 类来对 MapReduce Job 进行初始化，然后调用 setJobName() 方法命名这个 Job 。对Job进行合理的命名有助于 更快 地找到Job，以便在JobTracker和Tasktracker的页面中对其进行 监视 。<br>
<br>
</span></p>
<pre name="code" class="java">JobConf conf = new JobConf(WordCount. class ); conf.setJobName(&quot;wordcount&quot; );</pre><span style="font-size:18px"><br>
接着设置Job输出结果&lt;key,value&gt;的中key和value数据类型，因为结果是&lt;单词,个数&gt;，所以key设置为&quot;Text&quot;类型，相当于Java中String类型。Value设置为&quot;IntWritable&quot;，相当于Java中的int类型。<br>
</span><pre name="code" class="java">conf.setOutputKeyClass(Text.class );
conf.setOutputValueClass(IntWritable.class );</pre><span style="font-size:18px"><br>
然后设置Job处理的Map（拆分）、Combiner（中间结果合并）以及Reduce（合并）的相关处理类。这里用Reduce类来进行Map产生的中间结果合并，避免给网络数据传输产生压力。<br>
</span><pre name="code" class="java">conf.setMapperClass(Map.class );
conf.setCombinerClass(Reduce.class );
conf.setReducerClass(Reduce.class );</pre><span style="font-size:18px"><br>
接着就是调用setInputPath()和setOutputPath()设置输入输出路径。<br>
</span><pre name="code" class="java">conf.setInputFormat(TextInputFormat.class );
conf.setOutputFormat(TextOutputFormat.class );</pre><span style="font-size:18px"><br>
</span>
<p>
<h1><span style="font-size:18px">总结：</span></h1>
<p>
<p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; 任何技术都是一种思想的体现，而这个世界，我们最基本的一个算法就是分治法，这是我们拿在手里的一本百科全书，几乎可以解决我们80%的问题，而性能的问题尤其如此，我们经过了几百万年的演变，我们成为了地球上的强大智慧生物，我们本身就具有几百万年延续自己生命的强大竞争力，及我们几千年文明的积淀，我们现在遇到的问题，前人用文字书写在书上，我们一定可以找到，或者我们现在的生活，这个社会，也一定有这个问题的缩影！</span></p>
   
</div><div class="ArcitleLink"><a href='http://blog.csdn.net/xvshu/article/details/47090133'>原文链接</a>