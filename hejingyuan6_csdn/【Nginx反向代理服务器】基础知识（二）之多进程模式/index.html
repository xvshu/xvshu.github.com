<div style="color:blue" align=center>【Nginx反向代理服务器】基础知识（二）之多进程模式</div><br><div id="article_content" class="article_content tracking-ad" data-mod="popu_307" data-dsm="post">
<h1 style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">Nginx的多进程模式</span></h1><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">nginx在启动后，会有一个master进程和多个worker进程。master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。而基本的网络事件，则是放在worker进程中来处理了。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。nginx的进程模型，可以由下图来表示：</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;"><br></span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;"><img src="34115606368016" alt=""><br></span></p><p style="margin: 0in; font-size: 14pt;"><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;"><br></span></p><h2 style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">在nginx启动后，如果我们要操作nginx，要怎么做呢？</span></h2><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">从上文中我们可以看到，master来管理worker进程，所以我们只需要与master进程通信就行了。master进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill-HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><h2 style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">master进程在接收到HUP信号后是怎么做的呢？</span></h2><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx-s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">如何做到的呢？</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">我们还是拿reload来说，我们看到，执行命令时，我们是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><h2 style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">现在，我们知道了当我们在操作nginx的时候，nginx内部做了些什么事情，那么，worker进程又是如何处理请求的呢？</span></h2><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">我们前面有提到，worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><h2 style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">那么，nginx采用这种进程模型有什么好处呢？</span></h2><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">当然，好处肯定会很多了。首先，对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。当然，worker进程的异常退出，肯定是程序有bug了，异常退出，会导致当前worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。当然，好处还有很多，大家可以慢慢体会。</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><p style="margin: 0in; font-size: 14pt;"><span style="font-family:KaiTi_GB2312;">&nbsp;</span></p><h1><span style="font-family:KaiTi_GB2312;font-size:18px;">总结：</span></h1><span style="font-family:KaiTi_GB2312;font-size:18px;">&nbsp; &nbsp; &nbsp; &nbsp; 当然Nginx之所以如此高性能，还有如下的原因：<br><span style="white-space:pre">	</span>1，nginx代理和后端web服务器间无需长连接<br><span style="white-space:pre">	</span>2，接收用户请求是异步的，即先将用户请求全部接收下来，再一次性发送给后端服务器，极大的减轻后端web服务器压力<br><span style="white-space:pre">	</span>3，发送响应报文时，是边接收来自后端web服务器的数据，边发送给客户端的<br><span style="white-space:pre">	</span>4，对网络依赖性低，理论上讲，只要能够ping通就可以实施负载均衡<br></span><p><span style="font-family:KaiTi_GB2312;font-size:18px;">&nbsp; &nbsp; &nbsp; &nbsp; 5，支持服务器检测。nginx能够根据应用服务器处理页面返回的状态码，超时信息等检测服务器是否出现故障，并及时返回错误请求重新提交到其它节点上。</span></p><p><span style="font-family:KaiTi_GB2312;font-size:18px;"><br></span></p><p><span style="font-family:KaiTi_GB2312;font-size:18px;"><br></span></p><p><span style="font-family:KaiTi_GB2312;font-size:18px;"><br></span></p>   
</div><div class="ArcitleLink"><a href='http://blog.csdn.net/hejingyuan6/article/details/47250275'>原文链接</a>